{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data creation from IFC to Labeled point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import ifcopenshell.util\n",
    "import ifcopenshell.geom as geom\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting of general parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size_ref = 0.01 # voxel size for the downsampling\n",
    "voxel_size_target = 0.01\n",
    "init_radius = 0.15 # initial neirest neighbour search radius\n",
    "c2c_treshold = 0.15 # All points with a c2c-distance larger than this treshold will be labeled as clutter\n",
    "search_treshold = c2c_treshold # Max distance for normal comparison \n",
    "\n",
    "settings = geom.settings()\n",
    "settings.set(settings.USE_WORLD_COORDS, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting of the relevant file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifc_file = ifcopenshell.open(r\"D:\\SAM-Temp\\Projects\\2021-06-BIM-Gent Loesbergkaai\\MODELS\\IFC\\01203-40-BIM-Gent Loesbergkaai_3D Model IFC_R01.ifc\")\n",
    "pcd = o3d.io.read_point_cloud(r\"D:\\SAM-Temp\\Projects\\2021-06-BIM-Gent Loesbergkaai\\DATA\\PCD\\pointcloud.pcd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WALLS processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select all wall objects in the IFC file\n",
    "selector = Selector()\n",
    "walls = selector.parse(ifc_file, '.IfcWall') # This is equivalent to ifc.by_type('IfcWall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\MEET HET\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\MEET HET\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\MEET HET\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:296408)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\MEET HET\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\MEET HET\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "#Extract the mesh information from the IFC file\n",
    "meshinfo = []\n",
    "print(meshinfo)\n",
    "for ifc_entity in ifc_file.by_type(\"IfcWall\"):\n",
    "    # print(ifc_entity)\n",
    "    try: \n",
    "        shape = geom.create_shape(settings, ifc_entity)\n",
    "        ios_vertices = shape.geometry.verts\n",
    "        ios_faces = shape.geometry.faces\n",
    "\n",
    "        grouped_verts = [[ios_vertices[i], ios_vertices[i + 1], ios_vertices[i + 2]] for i in range(0, len(ios_vertices), 3)]\n",
    "        grouped_faces = [[ios_faces[i], ios_faces[i + 1], ios_faces[i + 2]] for i in range(0, len(ios_faces), 3)]\n",
    "\n",
    "        meshinfo.append([grouped_verts, grouped_faces])\n",
    "    except:\n",
    "        print(\"FAILED: shape creation\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\MEET HET\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\MEET HET\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\MEET HET\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:296408)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\MEET HET\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\MEET HET\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "#Create o3d mesh objects from the mesh info extracted from the BIM model.\n",
    "meshes = []\n",
    "for geometry in meshinfo:\n",
    "    vertices = o3d.utility.Vector3dVector(np.asarray(geometry[0]))\n",
    "    triangles = o3d.utility.Vector3iVector(np.asarray(geometry[1]))\n",
    "\n",
    "    mesh = o3d.geometry.TriangleMesh(vertices,triangles)\n",
    "\n",
    "    meshes.append(mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries(meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_walls = o3d.geometry.PointCloud()\n",
    "\n",
    "for submesh in meshes:\n",
    "    mesh_points = round(submesh.get_surface_area() * 1000)\n",
    "    submeshpcd = submesh.sample_points_uniformly(number_of_points = mesh_points, use_triangle_normal=True)\n",
    "    pcd_walls.__iadd__(submeshpcd)\n",
    "\n",
    "meshvox_walls = pcd_walls.voxel_down_sample(voxel_size_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge pointclouds from the meshes to 1 pointcloud and save labeles to a separate array\n",
    "# FAST method\n",
    "\n",
    "labels =[]\n",
    "label_id = [ \"Ceiling\", \"Floor\", \"Wall\", \"Beam\", \"Column\", \"Clutter\"]\n",
    "\n",
    "length_wall = len(meshvox_walls.points)\n",
    "i = 0\n",
    "while i < length_wall:\n",
    "    labels.append(\"2\")\n",
    "    i =  i+1\n",
    "\n",
    "meshpcd = o3d.geometry.PointCloud()\n",
    "meshpcd.__iadd__(meshvox_walls)\n",
    "print(meshpcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsampling of the real point cloud\n",
    "pcd = pcd.voxel_down_sample(voxel_size_target)\n",
    "#compute normals for the real pointcloud \n",
    "#TODO: Only when the real pointcloud does not contain normals\n",
    "pcd.estimate_normals()\n",
    "\n",
    "#compute the cloud to cloud distances between both downsmpled point clouds\n",
    "c2c = pcd.compute_point_cloud_distance(meshpcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter pointcloud on c2c distances\n",
    "# FAST method\n",
    "\n",
    "i=0\n",
    "percentage = 0\n",
    "Inlier_1_indeces = []\n",
    "Outlier_indeces = []\n",
    "\n",
    "while i < len(c2c):\n",
    "    if c2c[i] <= c2c_treshold:\n",
    "        np.asarray(pcd.colors)[i] = [0,1,0]\n",
    "        Inlier_1_indeces.append(i)\n",
    "    elif c2c[i] > c2c_treshold:\n",
    "        np.asarray(pcd.colors)[i] = [1,0,0]\n",
    "        Outlier_indeces.append(i)\n",
    "\n",
    "    progress = i/len(c2c)*100\n",
    "    \n",
    "    if progress >= percentage:\n",
    "        print(\"progress: %s %%\" %(round(progress)))\n",
    "        percentage = percentage + 5\n",
    "    i = i+1\n",
    "\n",
    "Final_inlier_pcd = pcd.select_by_index(Inlier_1_indeces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([meshpcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter pointcloud on normals and assign labels.\n",
    "\n",
    "\n",
    "i=0\n",
    "percentage = 0\n",
    "Inlier_2_indeces = []\n",
    "Final_inlier_labels = []\n",
    "Final_LOAs = []\n",
    "\n",
    "print(\"creating a KD-tree\")\n",
    "meshpcd_tree = o3d.geometry.KDTreeFlann(meshpcd)#Create KD tree index\n",
    "\n",
    "print(\"Finished creating a KD-tree\")\n",
    "progress = 0\n",
    "count = 0\n",
    "radius = init_radius\n",
    "\n",
    "for i in Inlier_1_indeces:\n",
    "    [k, idx, d] = meshpcd_tree.search_radius_vector_3d(pcd.points[i], init_radius) #Neighbour Search radius 10cm \n",
    "    # print(\"Selected points in the neighbourhood\")\n",
    "    # meshpcd_sample_points = np.asarray(meshpcd.points)[idx[:], :]\n",
    "    # meshpcd_sample_normals = np.asarray(meshpcd.normals)[idx[:], :]\n",
    "    Not_found = True\n",
    "    i1=0\n",
    "    while Not_found and i1 < len(idx) and len(idx) > 0:\n",
    "        if np.abs(np.dot(np.asarray(pcd.normals[i]), np.asarray(meshpcd.normals)[idx[i1],:])) > 0.9 or np.abs(d[i1]) < c2c_treshold/5:\n",
    "            Not_found = False\n",
    "            Inlier_2_indeces.append(i)\n",
    "            Final_inlier_labels.append(labels[idx[i1]])\n",
    "            Final_LOAs.append(d[i1]) \n",
    "        i1 = i1+1\n",
    "\n",
    "    if Not_found:\n",
    "        Outlier_indeces.append(i)\n",
    "\n",
    "    count = count + 1\n",
    "    progress = count/len(Inlier_1_indeces)*100\n",
    "    \n",
    "    if progress >= percentage:\n",
    "        print(\"progress: %s %%\" %(round(progress)))\n",
    "        percentage = percentage + 5\n",
    "\n",
    "\n",
    "print(\"extracting relevant points\")\n",
    "\n",
    "Final_inlier_pcd = pcd.select_by_index(Inlier_2_indeces)\n",
    "print(Final_inlier_pcd)\n",
    "Clutter_pcd = pcd.select_by_index(Outlier_indeces)\n",
    "print(Clutter_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "percentage = 0\n",
    "\n",
    "Class_0_indeces = []\n",
    "Class_0_points = 0\n",
    "Class_0_LOA30 = 0\n",
    "Class_0_LOA20 = 0\n",
    "Class_0_LOA10 = 0\n",
    "\n",
    "Class_1_indeces = []\n",
    "Class_1_points = 0\n",
    "Class_1_LOA30 = 0\n",
    "Class_1_LOA20 = 0\n",
    "Class_1_LOA10 = 0\n",
    "\n",
    "Class_2_indeces = []\n",
    "Class_2_points = 0\n",
    "Class_2_LOA30 = 0\n",
    "Class_2_LOA20 = 0\n",
    "Class_2_LOA10 = 0\n",
    "\n",
    "Class_3_indeces = []\n",
    "Class_3_points = 0\n",
    "Class_3_LOA30 = 0\n",
    "Class_3_LOA20 = 0\n",
    "Class_3_LOA10 = 0\n",
    "\n",
    "Class_4_indeces = []\n",
    "Class_4_points = 0\n",
    "Class_4_LOA30 = 0\n",
    "Class_4_LOA20 = 0\n",
    "Class_4_LOA10 = 0\n",
    "\n",
    "Class_clutter_points = len(Clutter_pcd.points)\n",
    "Clutter_pcd.paint_uniform_color([0.5,0.5,0.5]) #Grey\n",
    "Final_inlier_pcd.paint_uniform_color([0.5,0.5,0.5]) #Grey\n",
    "\n",
    "while i < len(np.asarray(Final_inlier_pcd.points)):\n",
    "    if Final_inlier_labels[i] == \"0\":\n",
    "        np.asarray(Final_inlier_pcd.colors)[i] = [0,0,0]\n",
    "        Class_0_indeces.append(i)\n",
    "        Class_0_points = Class_0_points + 1\n",
    "        dist = Final_LOAs[i]\n",
    "        if dist <= 0.015:\n",
    "            Class_0_LOA30 = Class_0_LOA30 + 1\n",
    "        elif dist > 0.015 and dist <=0.05:\n",
    "            Class_0_LOA20 = Class_0_LOA20 + 1\n",
    "        elif dist > 0.05:\n",
    "            Class_0_LOA10 = Class_0_LOA10 + 1\n",
    "\n",
    "    elif Final_inlier_labels[i] == \"1\":\n",
    "        np.asarray(Final_inlier_pcd.colors)[i] = [1,0,0]\n",
    "        Class_1_indeces.append(i)\n",
    "        Class_1_points = Class_1_points + 1\n",
    "        dist = Final_LOAs[i]\n",
    "        if dist <= 0.015:\n",
    "            Class_1_LOA30 = Class_1_LOA30 + 1\n",
    "        elif dist > 0.015 and dist <=0.05:\n",
    "            Class_1_LOA20 = Class_1_LOA20 + 1\n",
    "        elif dist > 0.05:\n",
    "            Class_1_LOA10 = Class_1_LOA10 + 1\n",
    "\n",
    "    elif Final_inlier_labels[i] == \"2\":\n",
    "        np.asarray(Final_inlier_pcd.colors)[i] = [0,1,0]\n",
    "        Class_2_indeces.append(i)\n",
    "        Class_2_points = Class_2_points + 1\n",
    "        dist = Final_LOAs[i]\n",
    "        if dist <= 0.015:\n",
    "            Class_2_LOA30 = Class_2_LOA30 + 1\n",
    "        elif dist > 0.015 and dist <=0.05:\n",
    "            Class_2_LOA20 = Class_2_LOA20 + 1\n",
    "        elif dist > 0.05:\n",
    "            Class_2_LOA10 = Class_2_LOA10 + 1\n",
    "\n",
    "    elif Final_inlier_labels[i] == \"3\":\n",
    "        np.asarray(Final_inlier_pcd.colors)[i] = [0,0,1]\n",
    "        Class_3_indeces.append(i)\n",
    "        Class_3_points = Class_3_points + 1\n",
    "        dist = Final_LOAs[i]\n",
    "        if dist <= 0.015:\n",
    "            Class_3_LOA30 = Class_3_LOA30 + 1\n",
    "        elif dist > 0.015 and dist <=0.05:\n",
    "            Class_3_LOA20 = Class_3_LOA20 + 1\n",
    "        elif dist > 0.05:\n",
    "            Class_3_LOA10 = Class_3_LOA10 + 1\n",
    "\n",
    "    elif Final_inlier_labels[i] == \"4\":\n",
    "        np.asarray(Final_inlier_pcd.colors)[i] = [1,1,0]\n",
    "        Class_4_indeces.append(i)\n",
    "        Class_4_points = Class_4_points + 1\n",
    "        dist = Final_LOAs[i]\n",
    "        if dist <= 0.015:\n",
    "            Class_4_LOA30 = Class_4_LOA30 + 1\n",
    "        elif dist > 0.015 and dist <=0.05:\n",
    "            Class_4_LOA20 = Class_4_LOA20 + 1\n",
    "        elif dist > 0.05:\n",
    "            Class_4_LOA10 = Class_4_LOA10 + 1\n",
    "\n",
    "    progress = i/len(np.asarray(Final_inlier_pcd.points))*100\n",
    "    if progress >= percentage:\n",
    "        print(\"progress: %s %%\" %(round(progress)))\n",
    "        percentage = percentage + 5\n",
    "    i= i+1\n",
    "\n",
    "print(\"...DONE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class 2:  %s \" % label_id[2])\n",
    "Class_2_pcd = Final_inlier_pcd.select_by_index(Class_2_indeces)\n",
    "print(Class_2_pcd)\n",
    "Class_2_filename = \"Cloud_\" + str(voxel_size_target) + \"_\" + label_id[2] + \".pcd\"\n",
    "Class_2_location = r\"C:\\Repo\\SCAN2BIM-python\\Samples\\Test-Loesberg\" +\"\\\\\" + Class_2_filename\n",
    "o3d.io.write_point_cloud(Class_2_location, Class_2_pcd, print_progress=True)\n",
    "print(\"Saved to:  %s \" % Class_2_location)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d72c4a735eb44b65cfd5c65b6aafb12e28e04b63b9d23d625bb4178b8a74524e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('scan2bim': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
